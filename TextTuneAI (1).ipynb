{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Dependencies**"
      ],
      "metadata": {
        "id": "XgUuXZrZ2nKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install einops\n",
        "# !pip install flashy\n",
        "# !pip install hydra-core\n",
        "# !pip install hydra-colorlog\n",
        "# !pip install julius\n",
        "# !pip install num2words\n",
        "# !pip install numpy\n",
        "# !pip install sentencepiece\n",
        "# !pip install spacy==3.7.2\n",
        "!pip install thinc==8.2.3\n",
        "# !pip install torch\n",
        "# !pip install torchaudio\n",
        "# !pip install huggingface_hub\n",
        "# !pip install tqdm\n",
        "# !pip install transformers\n",
        "# !pip install xformers\n",
        "# !pip install demucs\n",
        "# !pip install librosa\n",
        "# !pip install gradio\n",
        "# !pip install torchmetrics\n",
        "!pip install encodec\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHybgCVu2mWH",
        "outputId": "5fe28b81-946c-4566-d5f8-88340b387de2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thinc==8.2.3 in /usr/local/lib/python3.10/dist-packages (8.2.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc==8.2.3) (0.7.11)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from thinc==8.2.3) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from thinc==8.2.3) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from thinc==8.2.3) (3.0.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from thinc==8.2.3) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from thinc==8.2.3) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from thinc==8.2.3) (2.0.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc==8.2.3) (0.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from thinc==8.2.3) (67.7.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from thinc==8.2.3) (2.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from thinc==8.2.3) (23.2)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from thinc==8.2.3) (1.23.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->thinc==8.2.3) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->thinc==8.2.3) (2.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->thinc==8.2.3) (4.9.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: encodec in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from encodec) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from encodec) (2.1.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from encodec) (2.1.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from encodec) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->encodec) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->encodec) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->encodec) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->encodec) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Iterative Code**"
      ],
      "metadata": {
        "id": "VIeydambXkaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "def generate_audio(inp, model, duration):\n",
        "    processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
        "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "    sampling_rate = model.config.audio_encoder.sampling_rate\n",
        "    inputs = processor(\n",
        "        text=inp,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "\n",
        "    max_duration_tokens = int(duration * sampling_rate)\n",
        "\n",
        "    print(\"Generating audio...\")\n",
        "    with torch.no_grad():\n",
        "        audio_values = model.generate(\n",
        "            **inputs.to(device),\n",
        "            # do_sample=True,\n",
        "            # guidance_scale=3,\n",
        "            max_new_tokens=64\n",
        "        )\n",
        "\n",
        "    audio_data = audio_values[0, 0].cpu().numpy()\n",
        "    return audio_data, sampling_rate\n",
        "\n",
        "def process_input(user_input, artist_input, model, duration):\n",
        "    print(\"User input:\", user_input)\n",
        "    print(\"Artist input:\", artist_input)\n",
        "    print(\"Duration:\", duration)\n",
        "\n",
        "    s = \"\"\n",
        "    if user_input:\n",
        "        s += user_input + \", \"\n",
        "    if artist_input:\n",
        "        s += artist_input\n",
        "\n",
        "    print(\"Combined input:\", s)\n",
        "    if s and duration:\n",
        "        audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        return audio_data, sampling_rate\n",
        "    else:\n",
        "        print(\"Invalid input\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "\n",
        "    user_input = input(\"Enter user input: \")\n",
        "    artist_input = input(\"Enter artist input: \")\n",
        "    duration_input = input(\"Enter tune duration (in seconds): \")\n",
        "\n",
        "    audio_data, sampling_rate = process_input(user_input, artist_input, model, duration_input)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        # Display audio using IPython.display.Audio\n",
        "        display(Audio(audio_data, rate=sampling_rate))\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "pWG4q_CfFbJH",
        "outputId": "3700d337-c034-494d-9599-52b007cb9767"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter user input: asdadasd\n",
            "Enter artist input: fasfsdfs\n",
            "Enter tune duration (in seconds): 1\n",
            "User input: asdadasd\n",
            "Artist input: fasfsdfs\n",
            "Duration: 1\n",
            "Combined input: asdadasd, fasfsdfs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 1.06 MiB is free. Process 1236 has 5.32 GiB memory in use. Process 6492 has 6.14 GiB memory in use. Process 62859 has 3.29 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, and 100.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cf54705390ca>\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-cf54705390ca>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mduration_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter tune duration (in seconds): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martist_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maudio_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msampling_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cf54705390ca>\u001b[0m in \u001b[0;36mprocess_input\u001b[0;34m(user_input, artist_input, model, duration)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Combined input:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cf54705390ca>\u001b[0m in \u001b[0;36mgenerate_audio\u001b[0;34m(inp, model, duration)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/musicgen-small\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msampling_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     inputs = processor(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2570\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2571\u001b[0m                 )\n\u001b[0;32m-> 2572\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1157\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 1.06 MiB is free. Process 1236 has 5.32 GiB memory in use. Process 6492 has 6.14 GiB memory in use. Process 62859 has 3.29 GiB memory in use. Of the allocated memory 3.06 GiB is allocated by PyTorch, and 100.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/sample_data/text-tune-ai"
      ],
      "metadata": {
        "id": "EJ5336UMGqLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "1eti2RQIGyac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/audiocraft/\n"
      ],
      "metadata": {
        "id": "ukdJucOOIIKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "Upx7cRWOJBxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/sample_data/text-tune-ai\n"
      ],
      "metadata": {
        "id": "Mp_0f3dYJDz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "_2XO_bjzKCfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install audiocraft"
      ],
      "metadata": {
        "id": "Q35Vlle2Vx94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "ZnHGh20lQbUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchaudio, IPython\n",
        "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
        "from audiocraft.audiocraft.models import MusicGen\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration,sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def process_input(user_input, artist_input, model, duration):\n",
        "    print(\"User input:\", user_input)\n",
        "    print(\"Artist input:\", artist_input)\n",
        "    print(\"Duration:\", duration)\n",
        "    sr = 32000\n",
        "    s = \"\"\n",
        "    if user_input:\n",
        "        s += user_input + \", \"\n",
        "    if artist_input:\n",
        "        s += artist_input\n",
        "\n",
        "    print(\"Combined input:\", s)\n",
        "    if s and duration:\n",
        "        #audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        music_tensors = generate_music_tensors(s, model,duration,sr)\n",
        "        return music_tensors, sr\n",
        "    else:\n",
        "        print(\"Invalid input\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    #model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
        "\n",
        "    user_input = input(\"Enter user input: \")\n",
        "    artist_input = input(\"Enter your theme/tune mood: \")\n",
        "    duration_input = input(\"Enter tune duration (in seconds): \")\n",
        "\n",
        "    audio_data,sampling_rate  = process_input(user_input, artist_input, model, duration_input)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        # Display audio using IPython.display.Audio\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=32000))\n",
        "        #display(Audio(audio_data, rate=sampling_rate))\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "04cx_bhLQZNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchaudio, IPython\n",
        "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration,sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def process_input(user_prompt, theme, model, duration):\n",
        "    print(\"User input:\", user_prompt)\n",
        "    print(\"Theme:\", theme)\n",
        "    print(\"Duration:\", duration)\n",
        "    sr = 32000\n",
        "    s = \"\"\n",
        "    if user_prompt:\n",
        "        s += user_prompt + \", \"\n",
        "    if theme:\n",
        "        s += theme\n",
        "\n",
        "    print(\"Combined input:\", s)\n",
        "    if s and duration:\n",
        "        #audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        music_tensors = generate_music_tensors(s, model,duration,sr)\n",
        "        return music_tensors, sr\n",
        "    else:\n",
        "        print(\"Invalid input\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    #model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
        "\n",
        "    user_prompt = input(\"Enter user input: \")\n",
        "    theme = input(\"Enter your theme/tune mood: \")\n",
        "    duration = input(\"Enter tune duration (in seconds): \")\n",
        "\n",
        "    audio_data,sampling_rate  = process_input(user_prompt, theme, model, duration)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        # Display audio using IPython.display.Audio\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=32000))\n",
        "        #display(Audio(audio_data, rate=sampling_rate))\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "QN2mdkVGXhkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchaudio, IPython\n",
        "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration,sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def process_input(user_prompt, theme, model, duration,sr):\n",
        "    print(\"User input:\", user_prompt)\n",
        "    print(\"Theme:\", theme)\n",
        "    print(\"Duration:\", duration)\n",
        "    s = \"\"\n",
        "    if user_prompt:\n",
        "        s += user_prompt + \", \"\n",
        "    if theme:\n",
        "        s += theme\n",
        "\n",
        "    print(\"Combined prompt:\", s)\n",
        "    if s and duration:\n",
        "        #audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        music_tensors = generate_music_tensors(s, model,duration,sr)\n",
        "        return music_tensors, sr\n",
        "    else:\n",
        "        print(\"Invalid prompt\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    #model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
        "\n",
        "    user_prompt = input(\"Enter user input: \")\n",
        "    theme = input(\"Enter your theme/tune mood: \")\n",
        "    duration = input(\"Enter tune duration (in seconds): \")\n",
        "    sampling_rate = 32000\n",
        "\n",
        "    audio_data,sampling_rate  = process_input(user_prompt, theme, model, duration, sampling_rate)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=sampling_rate))\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "doV9gqExl0TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "zTO-7jGAuJjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchaudio, IPython\n",
        "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration,sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def process_input(user_prompt, theme, model, duration,sr):\n",
        "    print(\"User input:\", user_prompt)\n",
        "    print(\"Theme:\", theme)\n",
        "    print(\"Duration:\", duration)\n",
        "    s = \"\"\n",
        "    if user_prompt:\n",
        "        s += user_prompt + \", \"\n",
        "    if theme:\n",
        "        s += theme\n",
        "\n",
        "    print(\"Combined prompt:\", s)\n",
        "    if s and duration:\n",
        "        #audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        music_tensors = generate_music_tensors(s, model,duration,sr)\n",
        "        return music_tensors, sr\n",
        "    else:\n",
        "        print(\"Invalid prompt\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    #model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
        "\n",
        "    user_prompt = input(\"Enter user input: \")\n",
        "    theme = input(\"Enter your theme/tune mood: \")\n",
        "    duration = input(\"Enter tune duration (in seconds): \")\n",
        "    sampling_rate = 32000\n",
        "\n",
        "    audio_data,sampling_rate  = process_input(user_prompt, theme, model, duration, sampling_rate)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=sampling_rate))\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "S74CSz7_80LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchaudio, IPython\n",
        "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration,sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def process_input(user_prompt, theme, model, duration,sr):\n",
        "    print(\"User input:\", user_prompt)\n",
        "    print(\"Theme:\", theme)\n",
        "    print(\"Duration:\", duration)\n",
        "    s = \"\"\n",
        "    if user_prompt:\n",
        "        s += user_prompt + \", \"\n",
        "    if theme:\n",
        "        s += theme\n",
        "\n",
        "    print(\"Combined prompt:\", s)\n",
        "    if s and duration:\n",
        "        #audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        music_tensors = generate_music_tensors(s, model,duration,sr)\n",
        "        return music_tensors, sr\n",
        "    else:\n",
        "        print(\"Invalid prompt\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    #model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-stereo-small')\n",
        "\n",
        "    user_prompt = input(\"Enter user input: \")\n",
        "    theme = input(\"Enter your theme/tune mood: \")\n",
        "    duration = input(\"Enter tune duration (in seconds): \")\n",
        "    sampling_rate = 32000\n",
        "\n",
        "    audio_data,sampling_rate  = process_input(user_prompt, theme, model, duration, sampling_rate)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=sampling_rate))\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "JHULXfC4MayA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "vwvrcwbBtrSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchaudio, IPython\n",
        "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration,sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def process_input(user_prompt, theme, model, duration,sr):\n",
        "    print(\"User input:\", user_prompt)\n",
        "    print(\"Theme:\", theme)\n",
        "    print(\"Duration:\", duration)\n",
        "    s = \"\"\n",
        "    if user_prompt:\n",
        "        s += user_prompt + \", \"\n",
        "    if theme:\n",
        "        s += theme\n",
        "\n",
        "    print(\"Combined prompt:\", s)\n",
        "    if s and duration:\n",
        "        #audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        music_tensors = generate_music_tensors(s, model,duration,sr)\n",
        "        return music_tensors, sr\n",
        "    else:\n",
        "        print(\"Invalid prompt\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    #model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-stereo-small')\n",
        "\n",
        "    user_prompt = input(\"Enter user input: \")\n",
        "    theme = input(\"Enter your theme/tune mood: \")\n",
        "    duration = input(\"Enter tune duration (in seconds): \")\n",
        "    sampling_rate = 32000\n",
        "\n",
        "    audio_data,sampling_rate  = process_input(user_prompt, theme, model, duration, sampling_rate)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=sampling_rate))\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "E5cThraJwFgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade openai"
      ],
      "metadata": {
        "id": "HTOFC4ywzUYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchaudio, IPython\n",
        "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import Audio, display\n",
        "import openai\n",
        "\n",
        "\n",
        "def query_gpt(user_prompt, theme):\n",
        "    openai.api_key = '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'\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a music expert, skilled in explaining intricacies in music vibe with contextual flair.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"I am trying to get a highlevel description for {user_prompt} vibe of music for {theme} purpose. Can you please give me that one line music vibe explaining the rhythm.\"}\n",
        "            ]\n",
        "        )\n",
        "        print(f\"GPT Response: {response}\")\n",
        "        #print(response['choices'][0]['message']['content'])\n",
        "        #return response['choices'][0]['message']['content']\n",
        "        if response.choices:\n",
        "            choice = response.choices[0]\n",
        "            if choice.finish_reason == \"stop\":\n",
        "                message = choice.message\n",
        "                content = message.content\n",
        "                print(\"Content:\", content)\n",
        "                return content\n",
        "        else:\n",
        "            print(\"No choices found in the response\")\n",
        "            return \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle any exception that occurs during the OpenAI API request\n",
        "        print(f\"An error occurred during the OpenAI API request: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration,sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def process_input(user_prompt, theme, model, duration,sr):\n",
        "    print(\"User input:\", user_prompt)\n",
        "    print(\"Theme:\", theme)\n",
        "    print(\"Duration:\", duration)\n",
        "    s = \"\"\n",
        "    if user_prompt:\n",
        "        s += user_prompt + \", \"\n",
        "    if (theme != \"\"):\n",
        "        res = query_gpt(user_prompt,theme)\n",
        "        if (res != \"\"):\n",
        "            s += res\n",
        "\n",
        "\n",
        "    print(\"Combined prompt:\", s)\n",
        "    if s and duration:\n",
        "        #audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        music_tensors = generate_music_tensors(s, model,duration,sr)\n",
        "        return music_tensors, sr\n",
        "    else:\n",
        "        print(\"Invalid prompt\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    #model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-stereo-small')\n",
        "\n",
        "    user_prompt = input(\"Enter user input: \")\n",
        "    theme = input(\"Enter your theme/tune mood: \")\n",
        "    duration = input(\"Enter tune duration (in seconds): \")\n",
        "    sampling_rate = 32000\n",
        "\n",
        "    audio_data,sampling_rate  = process_input(user_prompt, theme, model, duration, sampling_rate)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=sampling_rate))\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "NghKQPnnmlUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchaudio, IPython\n",
        "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration,sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def process_input(user_prompt, theme, model, duration,sr):\n",
        "    print(\"User input:\", user_prompt)\n",
        "    print(\"Theme:\", theme)\n",
        "    print(\"Duration:\", duration)\n",
        "    s = \"\"\n",
        "    if user_prompt:\n",
        "        s += user_prompt + \", \"\n",
        "    if theme:\n",
        "        s += theme\n",
        "\n",
        "    print(\"Combined prompt:\", s)\n",
        "    if s and duration:\n",
        "        #audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        music_tensors = generate_music_tensors(s, model,duration,sr)\n",
        "        return music_tensors, sr\n",
        "    else:\n",
        "        print(\"Invalid prompt\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    #model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-stereo-small')\n",
        "\n",
        "    user_prompt = input(\"Enter user input: \")\n",
        "    theme = input(\"Enter your theme/tune mood: \")\n",
        "    duration = input(\"Enter tune duration (in seconds): \")\n",
        "    sampling_rate = 32000\n",
        "\n",
        "    audio_data,sampling_rate  = process_input(user_prompt, theme, model, duration, sampling_rate)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=sampling_rate))\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "sAEi9WfKANCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchaudio, IPython\n",
        "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration,sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def process_input(user_prompt, theme, model, duration,sr):\n",
        "    print(\"User input:\", user_prompt)\n",
        "    print(\"Theme:\", theme)\n",
        "    print(\"Duration:\", duration)\n",
        "    s = \"\"\n",
        "    if user_prompt:\n",
        "        s += user_prompt + \", \"\n",
        "    if theme:\n",
        "        s += theme\n",
        "\n",
        "    print(\"Combined prompt:\", s)\n",
        "    if s and duration:\n",
        "        #audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        music_tensors = generate_music_tensors(s, model,duration,sr)\n",
        "        return music_tensors, sr\n",
        "    else:\n",
        "        print(\"Invalid prompt\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    #model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-stereo-small')\n",
        "\n",
        "    user_prompt = input(\"Enter user input: \")\n",
        "    theme = input(\"Enter your theme/tune mood: \")\n",
        "    duration = input(\"Enter tune duration (in seconds): \")\n",
        "    sampling_rate = 32000\n",
        "\n",
        "    audio_data,sampling_rate  = process_input(user_prompt, theme, model, duration, sampling_rate)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=sampling_rate))\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "9YxoUm6vCBb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/sample_data/text-tune-ai\n",
        "!git clone https://github.com/facebookresearch/audiocraft/\n",
        "%cd /content/sample_data/text-tune-ai\n",
        "!pip install audiocraft"
      ],
      "metadata": {
        "id": "WLZtwWpUgrEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "HQ5-tkKOgzyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLAP"
      ],
      "metadata": {
        "id": "vKKa9Q5T7oxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchaudio, IPython\n",
        "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration,sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def process_input(user_prompt, theme, model, duration,sr):\n",
        "    print(\"User input:\", user_prompt)\n",
        "    print(\"Theme:\", theme)\n",
        "    print(\"Duration:\", duration)\n",
        "    s = \"\"\n",
        "    if user_prompt:\n",
        "        s += user_prompt + \", \"\n",
        "    if theme:\n",
        "        s += theme\n",
        "\n",
        "    print(\"Combined prompt:\", s)\n",
        "    if s and duration:\n",
        "        #audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        music_tensors = generate_music_tensors(s, model,duration,sr)\n",
        "        return music_tensors, sr\n",
        "    else:\n",
        "        print(\"Invalid prompt\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    #model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-stereo-small')\n",
        "\n",
        "    user_prompt = input(\"Enter user input: \")\n",
        "    theme = input(\"Enter your theme/tune mood: \")\n",
        "    duration = input(\"Enter tune duration (in seconds): \")\n",
        "    sampling_rate = 48000\n",
        "\n",
        "    audio_data,sampling_rate  = process_input(user_prompt, theme, model, duration, sampling_rate)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=sampling_rate))\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Z_vpEEDX7nxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, IPython\n",
        "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration,sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def process_input(user_prompt, theme, model, duration,sr):\n",
        "    print(\"User input:\", user_prompt)\n",
        "    print(\"Theme:\", theme)\n",
        "    print(\"Duration:\", duration)\n",
        "    s = \"\"\n",
        "    if user_prompt:\n",
        "        s += user_prompt + \", \"\n",
        "    if theme:\n",
        "        s += theme\n",
        "\n",
        "    print(\"Combined prompt:\", s)\n",
        "    if s and duration:\n",
        "        #audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        music_tensors = generate_music_tensors(s, model,duration,sr)\n",
        "        return music_tensors, sr\n",
        "    else:\n",
        "        print(\"Invalid prompt\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    #model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-stereo-small')\n",
        "\n",
        "    user_prompt = input(\"Enter user input: \")\n",
        "    theme = input(\"Enter your theme/tune mood: \")\n",
        "    duration = input(\"Enter tune duration (in seconds): \")\n",
        "    sampling_rate = 48000\n",
        "\n",
        "    audio_data,sampling_rate  = process_input(user_prompt, theme, model, duration, sampling_rate)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=sampling_rate))\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "hZsqjvEjMjk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/mikexue7/audiocraft.git"
      ],
      "metadata": {
        "id": "T7iaUvCjauPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import display\n",
        "from scipy.io import wavfile\n",
        "\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration,sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def process_input(user_prompt, theme, model, duration,sr):\n",
        "    print(\"User input:\", user_prompt)\n",
        "    print(\"Theme:\", theme)\n",
        "    print(\"Duration:\", duration)\n",
        "    s = \"\"\n",
        "    if user_prompt:\n",
        "        s += user_prompt + \", \"\n",
        "    if theme:\n",
        "        s += theme\n",
        "\n",
        "    print(\"Combined prompt:\", s)\n",
        "    if s and duration:\n",
        "        #audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        music_tensors = generate_music_tensors(s, model,duration,sr)\n",
        "        return music_tensors, sr\n",
        "    else:\n",
        "        print(\"Invalid prompt\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    #model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
        "\n",
        "    user_prompt = input(\"Enter user input: \")\n",
        "    theme = input(\"Enter your theme/tune mood: \")\n",
        "    duration = input(\"Enter tune duration (in seconds): \")\n",
        "    sampling_rate = 32000\n",
        "\n",
        "    audio_data,sampling_rate  = process_input(user_prompt, theme, model, duration, sampling_rate)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=sampling_rate))\n",
        "        wavfile.write(\"/content/sample_data/text-tune-ai/output/download2.wav\", rate=sampling_rate, data=audio_data[0, 0].cpu().numpy())\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ob12Dy5ge2I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "kkVMBfHlyT7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import display\n",
        "from scipy.io import wavfile\n",
        "import openai\n",
        "\n",
        "\n",
        "def query_gpt(user_prompt, theme):\n",
        "    openai.api_key = 'Enter the Key'\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a music expert, skilled in explaining intricacies in music vibe with contextual flair.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"I am trying to get a highlevel description for {user_prompt} vibe of music for {theme} purpose. Can you please give me that one line music vibe explaining the rhythm.\"}\n",
        "            ]\n",
        "        )\n",
        "        print(f\"GPT Response: {response}\")\n",
        "        #print(response['choices'][0]['message']['content'])\n",
        "        #return response['choices'][0]['message']['content']\n",
        "        if response.choices:\n",
        "            choice = response.choices[0]\n",
        "            if choice.finish_reason == \"stop\":\n",
        "                message = choice.message\n",
        "                content = message.content\n",
        "                print(\"Content:\", content)\n",
        "                return content\n",
        "        else:\n",
        "            print(\"No choices found in the response\")\n",
        "            return \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle any exception that occurs during the OpenAI API request\n",
        "        print(f\"An error occurred during the OpenAI API request: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration,sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def process_input(user_prompt, theme, model, duration,sr):\n",
        "    print(\"User input:\", user_prompt)\n",
        "    print(\"Theme:\", theme)\n",
        "    print(\"Duration:\", duration)\n",
        "    s = \"\"\n",
        "    if user_prompt:\n",
        "        s += user_prompt + \", \"\n",
        "    if (theme != \"\"):\n",
        "        res = query_gpt(user_prompt,theme)\n",
        "        if (res != \"\"):\n",
        "            s += res\n",
        "\n",
        "\n",
        "    print(\"Combined prompt:\", s)\n",
        "    if s and duration:\n",
        "        #audio_data, sampling_rate = generate_audio(s, model, float(duration))\n",
        "        music_tensors = generate_music_tensors(s, model,duration,sr)\n",
        "        return music_tensors, sr\n",
        "    else:\n",
        "        print(\"Invalid prompt\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    #model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
        "\n",
        "    user_prompt = input(\"Enter user input: \")\n",
        "    theme = input(\"Enter your theme/tune mood: \")\n",
        "    duration = input(\"Enter tune duration (in seconds): \")\n",
        "    sampling_rate = 32000\n",
        "\n",
        "    audio_data,sampling_rate  = process_input(user_prompt, theme, model, duration, sampling_rate)\n",
        "\n",
        "    if audio_data is not None and sampling_rate is not None:\n",
        "        print(\"Audio file generated\")\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=sampling_rate))\n",
        "        wavfile.write(\"/content/sample_data/text-tune-ai/output/download3.wav\", rate=sampling_rate, data=audio_data[0, 0].cpu().numpy())\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "jp29oZ-eyMnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import display\n",
        "from scipy.io import wavfile\n",
        "import openai\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "def query_gpt(user_prompt, theme):\n",
        "    openai.api_key = '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'\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a music expert, skilled in explaining intricacies in music vibe with contextual flair.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"I am trying to get a highlevel description for {user_prompt} vibe of music for {theme} purpose. Can you please give me that one line music vibe explaining the rhythm.\"}\n",
        "            ]\n",
        "        )\n",
        "        print(f\"GPT Response: {response}\")\n",
        "        if response.choices:\n",
        "            choice = response.choices[0]\n",
        "            if choice.finish_reason == \"stop\":\n",
        "                message = choice.message\n",
        "                content = message.content\n",
        "                print(\"Content:\", content)\n",
        "                return content\n",
        "        else:\n",
        "            print(\"No choices found in the response\")\n",
        "            return \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the OpenAI API request: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration, sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def compute_fad_score(generated_audio, target_audio, sr):\n",
        "    gen_spec = np.abs(librosa.stft(generated_audio.squeeze().cpu().numpy()))\n",
        "    target_spec = np.abs(librosa.stft(target_audio.squeeze()))\n",
        "    fad_score = np.mean(np.abs(gen_spec - target_spec))\n",
        "    return fad_score\n",
        "\n",
        "def process_input(user_prompt, theme, model, duration, sr):\n",
        "    print(\"User input:\", user_prompt)\n",
        "    print(\"Theme:\", theme)\n",
        "    print(\"Duration:\", duration)\n",
        "    s = \"\"\n",
        "    if user_prompt:\n",
        "        s += user_prompt + \", \"\n",
        "    if theme != \"\":\n",
        "        res = query_gpt(user_prompt, theme)\n",
        "        if res != \"\":\n",
        "            s += res\n",
        "\n",
        "    print(\"Combined prompt:\", s)\n",
        "    if s and duration:\n",
        "        music_tensors = generate_music_tensors(s, model, duration, sr)\n",
        "        return music_tensors, s\n",
        "    else:\n",
        "        print(\"Invalid prompt\")\n",
        "        return None, None\n",
        "\n",
        "def main():\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
        "\n",
        "    user_prompt = input(\"Enter user input: \")\n",
        "    theme = input(\"Enter your theme/tune mood: \")\n",
        "    duration = input(\"Enter tune duration (in seconds): \")\n",
        "    sampling_rate = 32000\n",
        "\n",
        "    audio_data, theme_description = process_input(user_prompt, theme, model, duration, sampling_rate)\n",
        "\n",
        "    if audio_data is not None and theme_description is not None:\n",
        "        print(\"Audio file generated\")\n",
        "\n",
        "        IPython.display.display(IPython.display.Audio(audio_data.cpu().numpy().squeeze(), rate=sampling_rate))\n",
        "        wavfile.write(\"/content/sample_data/text-tune-ai/output/download3.wav\", rate=sampling_rate, data=audio_data[0, 0].cpu().numpy())\n",
        "        # Assuming you have a target audio file for comparison\n",
        "        target_audio, _ = librosa.load('/content/sample_data/text-tune-ai/output/download2.wav', sr=sampling_rate)\n",
        "\n",
        "        # Calculate FAD Score\n",
        "        fad_score = compute_fad_score(audio_data, target_audio, sampling_rate)\n",
        "        print(\"FAD Score:\", fad_score)\n",
        "\n",
        "    else:\n",
        "        print(\"There is something wrong with the audio generation\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ecSatZhI1zuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "pIRT8p24ju_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/sample_data/text-tune-ai\n",
        "!git clone https://github.com/facebookresearch/audiocraft/\n",
        "%cd /content/sample_data/text-tune-ai\n",
        "!pip install -r requirements.txt\n",
        "! pip install datasets\n",
        "!pip install audiocraft"
      ],
      "metadata": {
        "id": "-6zD5p4M-AGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from audiocraft.models import MusicGen\n",
        "from IPython.display import display\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "def generate_music_tensors(prompt, model, duration, sr):\n",
        "    model.set_generation_params(\n",
        "        use_sampling=True,\n",
        "        top_k=250,\n",
        "        duration=int(duration)\n",
        "    )\n",
        "    print(\"Your custom tune is under generation....\")\n",
        "    output = model.generate(\n",
        "        descriptions=[prompt],\n",
        "        progress=True,\n",
        "        return_tokens=True\n",
        "    )\n",
        "\n",
        "    audio = output[0]\n",
        "    return audio[:, :int(float(duration) * sr)]\n",
        "\n",
        "def compute_fad_score(generated_audio, target_audio, sr):\n",
        "    gen_spec = np.abs(librosa.stft(generated_audio.squeeze().cpu().numpy()))\n",
        "    target_spec = np.abs(librosa.stft(target_audio.squeeze()))\n",
        "    fad_score = np.mean(np.abs(gen_spec - target_spec))\n",
        "    return fad_score\n",
        "\n",
        "def get_caption_audio(musiccaps_data, prompt):\n",
        "  filtered_data = musiccaps_data.filter(\n",
        "      lambda example: example[\"caption\"].strip().lower().find(prompt.lower()) != -1\n",
        "  )\n",
        "\n",
        "  caption = filtered_data[\"caption\"][0]\n",
        "  audio_path = filtered_data[\"audio_path\"][0]\n",
        "\n",
        "  audio, _ = librosa.load(audio_path, sr=32000)\n",
        "  return caption, audio\n",
        "\n",
        "def main():\n",
        "    musiccaps_data = load_dataset(\"google/MusicCaps\")\n",
        "\n",
        "    num_prompts = 10\n",
        "    model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
        "    duration = 10\n",
        "    sampling_rate = 32000\n",
        "\n",
        "    captions = musiccaps_data[\"train\"][\"caption\"]\n",
        "    prompts = captions[:num_prompts]\n",
        "\n",
        "    all_fad_scores = []\n",
        "    for prompt in prompts:\n",
        "        music_tensors = generate_music_tensors(prompt, model, duration, sampling_rate)\n",
        "        caption, target_audio = get_caption_audio(musiccaps_data, prompt)\n",
        "        fad_score = compute_fad_score(music_tensors, target_audio, sampling_rate)\n",
        "        all_fad_scores.append(fad_score)\n",
        "        print(f\"FAD Score for '{prompt}':\", fad_score)\n",
        "\n",
        "    if all_fad_scores:\n",
        "        average_fad_score = sum(all_fad_scores) / len(all_fad_scores)\n",
        "        print(f\"Average FAD Score for {num_prompts} prompts:\", average_fad_score)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "EfmQjQE-i0DQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}